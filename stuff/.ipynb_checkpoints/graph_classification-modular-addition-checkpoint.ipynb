{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6399fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "55814e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 2\n",
    "out_dim = 113\n",
    "hidden_dim = 128\n",
    "heads = 4\n",
    "class GATV3(torch.nn.Module):\n",
    "  def __init__(self, num_layers=1, dim_model=128, num_heads=4, num_tokens=114, seq_len=3):\n",
    "    super().__init__()\n",
    "    self.conv = GATConv(dim_model, dim_model, num_heads=heads).to(torch.float64)\n",
    "    self.linear = nn.Linear(dim_model, num_tokens - 1).to(torch.float64) \n",
    "\n",
    "    self.token_embeddings = nn.Embedding(num_tokens, dim_model).to(torch.float64)  # We have p+1 input tokens: 0,1,...,113.\n",
    "    self.position_embeddings = nn.Embedding(seq_len, dim_model).to(torch.float64)   # We length 3 sequences, e.g. (10, 25, 113)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    token_embedding = self.token_embeddings(inputs)\n",
    "    \n",
    "    positions = repeat(torch.arange(inputs.shape[1]), \"p -> b p\", b = inputs.shape[0])\n",
    "    position_embedding = self.position_embeddings(positions)\n",
    "    \n",
    "    embedding = token_embedding + position_embedding\n",
    "\n",
    "    #embedding = rearrange(embedding, 'b s d -> s b d')\n",
    "    \n",
    "    res = torch.Tensor([])\n",
    "    for i in range(embedding.shape[0]):\n",
    "        x = self.conv(embedding[i], edge_index)\n",
    "        x = self.linear(x)\n",
    "        x = torch.mean(x, dim=0)\n",
    "        res = torch.cat([res, x.reshape(1, -1)], dim=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "63b10d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1cd26cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "edge_index = torch.Tensor(nx.adjacency_matrix(nx.random_regular_graph(2,3)).todense()).nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1abc079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for dataset\n",
    "n = 2000\n",
    "p = 0.001\n",
    "prime = 113\n",
    "threshold = 0.8\n",
    "no_digits = 4\n",
    "\n",
    "# Params for GNN\n",
    "input_dim = 1\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "\n",
    "# Params for optimizer\n",
    "weight_decay = 3\n",
    "lr = 1e-3\n",
    "betas = (0.9, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2aaeb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6ebc5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats = torch.Tensor([])\n",
    "for i in range(lim):\n",
    "    for j in range(lim):\n",
    "        node_feats = torch.cat([node_feats, torch.Tensor([[i, j, 113]])], dim=0)\n",
    "node_feats = node_feats.to(torch.int64)\n",
    "\n",
    "node_labels = (node_feats[: ,0] + node_feats[: ,1]) % 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d43865e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "poss = [i for i in range(lim**2)]\n",
    "idx = random.sample(poss, int(threshold * len(poss)))\n",
    "train_mask = [True if i in idx else False for i in range(lim**2)]\n",
    "val_mask = [False if train_mask[i] else True for i in range(lim**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff46cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 1/1000 [00:01<17:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(4.9347, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9640, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 11/1000 [00:11<17:05,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(4.0690, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2685, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 21/1000 [00:21<17:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.7626, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1873, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                       | 31/1000 [00:32<17:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.5485, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1870, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                       | 41/1000 [00:43<16:54,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.3799, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1856, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 51/1000 [00:53<16:51,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.2434, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1793, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                      | 61/1000 [01:04<16:35,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.1371, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1875, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                      | 71/1000 [01:14<15:57,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.0558, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1891, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                     | 81/1000 [01:25<15:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.9926, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1938, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                     | 91/1000 [01:35<16:03,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.9420, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2020, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 101/1000 [01:46<15:39,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.8999, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2146, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                   | 111/1000 [01:56<15:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.8631, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2304, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▊                                   | 121/1000 [02:07<15:27,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.8295, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2484, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                  | 131/1000 [02:17<15:10,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.7977, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2629, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 141/1000 [02:28<15:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.7666, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2683, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                  | 151/1000 [02:38<14:45,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.7359, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2628, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                 | 161/1000 [02:49<14:49,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.7044, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2553, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▊                                 | 171/1000 [02:59<14:22,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.6745, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2529, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                | 181/1000 [03:09<14:08,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.6394, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2344, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▋                                | 191/1000 [03:20<14:13,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.5880, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1872, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 201/1000 [03:30<14:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.5206, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0937, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▍                               | 211/1000 [03:41<13:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.4548, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0502, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▊                               | 221/1000 [03:52<13:29,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.3937, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9982, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▏                              | 231/1000 [04:02<13:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.3316, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9433, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▋                              | 241/1000 [04:13<13:31,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.2649, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8573, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████                              | 251/1000 [04:23<13:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.2068, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7837, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▍                             | 261/1000 [04:34<12:38,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.1524, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7107, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▊                             | 271/1000 [04:44<12:45,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.1045, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6388, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▏                            | 281/1000 [04:54<12:12,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.0610, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5694, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▋                            | 291/1000 [05:05<12:14,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.0220, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5114, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 301/1000 [05:15<12:18,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.9868, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4623, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████▍                           | 311/1000 [05:26<11:55,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.9572, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4259, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▊                           | 321/1000 [05:36<11:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.9286, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3928, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▏                          | 331/1000 [05:47<11:47,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.9034, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3704, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▋                          | 341/1000 [05:57<11:21,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.8815, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3523, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████                          | 351/1000 [06:07<10:51,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.8583, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3344, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▍                         | 361/1000 [06:18<11:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.8381, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3211, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▊                         | 371/1000 [06:29<11:13,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.8182, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3110, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████▏                        | 381/1000 [06:39<10:42,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.8001, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3013, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████▋                        | 391/1000 [06:50<10:58,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7866, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2953, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████                        | 401/1000 [07:00<10:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7708, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2841, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████▍                       | 411/1000 [07:11<10:25,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7565, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2785, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▊                       | 421/1000 [07:22<10:25,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7413, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2728, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▏                      | 431/1000 [07:32<09:49,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7312, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2657, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▋                      | 441/1000 [07:42<09:46,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7198, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2601, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████                      | 451/1000 [07:53<09:46,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.7087, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2492, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▍                     | 461/1000 [08:03<09:25,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.6977, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2441, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████▊                     | 471/1000 [08:14<09:13,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.6857, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2414, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████▏                    | 481/1000 [08:25<09:12,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(1.6792, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2384, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████▌                    | 488/1000 [08:32<08:59,  1.05s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = GATV3()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(node_feats)  # Perform a single forward pass.\n",
    "      out = out.to(torch.float64)\n",
    "\n",
    "\n",
    "      loss = criterion(out[train_mask], node_labels[train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss_test = criterion(out[val_mask], node_labels[val_mask])\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss, loss_test\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      pred = model(node_feats)\n",
    "      pred = pred.argmax(dim=1)  # Use the class with highest probability.\n",
    "      #true = node_labels.argmax(dim=1)\n",
    "    \n",
    "#       test_acc = torch.sqrt(torch.mean((pred[val_mask] - node_labels[val_mask]) ** 2))\n",
    "#       train_acc = torch.sqrt(torch.mean((pred[train_mask] - node_labels[train_mask]) ** 2))\n",
    "\n",
    "    \n",
    "#       return test_acc.item(), train_acc.item()\n",
    "      return (accuracy_score(node_labels[val_mask], pred[val_mask]),\n",
    "            accuracy_score(node_labels[train_mask], pred[train_mask]))\n",
    "\n",
    "# def train():\n",
    "#       model.train()\n",
    "#       optimizer.zero_grad()  # Clear gradients.\n",
    "#       out = model(node_feats, adj_matrix)  # Perform a single forward pass.\n",
    "#       loss = criterion(out[train_mask], node_labels[train_mask])  # Compute the loss solely based on the training nodes.\n",
    "#       loss_test = criterion(out[val_mask], node_labels[val_mask])\n",
    "#       loss.backward()  # Derive gradients.\n",
    "#       optimizer.step()  # Update parameters based on gradients.\n",
    "#       return loss, loss_test\n",
    "\n",
    "# def test():\n",
    "#       model.eval()\n",
    "#       out = model(node_feats, adj_matrix)\n",
    "#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "#       true = node_labels.argmax(dim=1)\n",
    "#       test_correct = pred[val_mask] == true[val_mask]  # Check against ground-truth labels.\n",
    "#       test_acc = int(np.array(test_correct).sum()) / int(np.array(val_mask).sum())  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "#       train_correct = pred[train_mask] == true[train_mask]  # Check against ground-truth labels.\n",
    "#       train_acc = int(np.array(train_correct).sum()) / int(np.array(train_mask).sum())  # Derive ratio of correct predictions.\n",
    "#       return test_acc, train_acc\n",
    "import tqdm.auto as tqdm\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_aa = []\n",
    "train_aa = []\n",
    "for epoch in tqdm.tqdm(range(1000)):\n",
    "#     if epoch % 100 == 0:\n",
    "#       print(epoch)\n",
    "    loss, loss_test = train()\n",
    "    test_acc, train_acc = test()\n",
    "    train_loss.append(loss.item())\n",
    "    test_loss.append(loss_test.item())\n",
    "    test_aa.append(test_acc)\n",
    "    train_aa.append(train_acc)\n",
    "    if epoch % 10 == 0:\n",
    "        print('train test')\n",
    "        print(loss)\n",
    "        print(loss_test)\n",
    "        print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a9413f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6565, -0.1264, -0.4744],\n",
       "         [-0.7860, -0.2021,  1.3956],\n",
       "         [-0.3140, -0.5562,  0.3549],\n",
       "         [-0.2646, -1.6739,  0.7716]],\n",
       "\n",
       "        [[-0.3312,  0.6003,  0.3360],\n",
       "         [ 0.4989, -0.6734,  1.2114],\n",
       "         [ 1.4119,  0.3367,  0.4190],\n",
       "         [-2.5377,  0.8328, -2.8228]]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(torch.randn(2,3,4), 'a b c -> a c b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd8378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df457726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa5bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f2647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

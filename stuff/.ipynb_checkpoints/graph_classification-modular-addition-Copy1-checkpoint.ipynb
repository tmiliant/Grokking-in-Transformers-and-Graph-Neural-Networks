{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6399fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, repeat\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55814e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 2\n",
    "out_dim = 113\n",
    "hidden_dim = 128\n",
    "heads = 4\n",
    "class GATV3(torch.nn.Module):\n",
    "  def __init__(self, num_layers=1, dim_model=128, num_heads=4, num_tokens=114, seq_len=3):\n",
    "    super().__init__()\n",
    "    self.conv = GATConv(dim_model, dim_model, num_heads=heads).to(torch.float64)\n",
    "    self.linear = nn.Linear(dim_model, num_tokens - 1).to(torch.float64) \n",
    "\n",
    "    self.token_embeddings = nn.Embedding(num_tokens, dim_model).to(torch.float64)  # We have p+1 input tokens: 0,1,...,113.\n",
    "    self.position_embeddings = nn.Embedding(seq_len, dim_model).to(torch.float64)   # We length 3 sequences, e.g. (10, 25, 113)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    token_embedding = self.token_embeddings(inputs)\n",
    "    \n",
    "    positions = repeat(torch.arange(inputs.shape[1]), \"p -> b p\", b = inputs.shape[0])\n",
    "    position_embedding = self.position_embeddings(positions)\n",
    "    \n",
    "    embedding = token_embedding + position_embedding\n",
    "\n",
    "    #embedding = rearrange(embedding, 'b s d -> s b d')\n",
    "    \n",
    "    res = torch.Tensor([])\n",
    "    for i in range(embedding.shape[0]):\n",
    "        x = self.conv(embedding[i], edge_index)\n",
    "        x = self.linear(x)\n",
    "        x = torch.mean(x, dim=0)\n",
    "        res = torch.cat([res, x.reshape(1, -1)], dim=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b10d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd26cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "edge_index = torch.Tensor(nx.adjacency_matrix(nx.random_regular_graph(2,3)).todense()).nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abc079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for dataset\n",
    "n = 2000\n",
    "p = 0.001\n",
    "prime = 113\n",
    "threshold = 0.3\n",
    "no_digits = 4\n",
    "\n",
    "# Params for GNN\n",
    "input_dim = 1\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "\n",
    "# Params for optimizer\n",
    "weight_decay = 3\n",
    "lr = 1e-3\n",
    "betas = (0.9, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79467774",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebc5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats = torch.Tensor([])\n",
    "for i in range(lim):\n",
    "    for j in range(lim):\n",
    "        node_feats = torch.cat([node_feats, torch.Tensor([[i, j, 113]])], dim=0)\n",
    "node_feats = node_feats.to(torch.int64)\n",
    "\n",
    "node_labels = (node_feats[: ,0] + node_feats[: ,1]) % 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43865e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "poss = [i for i in range(lim**2)]\n",
    "idx = random.sample(poss, int(threshold * len(poss)))\n",
    "train_mask = [True if i in idx else False for i in range(lim**2)]\n",
    "val_mask = [False if train_mask[i] else True for i in range(lim**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff46cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 1/1000 [00:00<16:22,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(4.8870, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8466, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 11/1000 [00:10<16:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.9065, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3486, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 21/1000 [00:20<16:26,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.3496, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3192, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                       | 31/1000 [00:30<16:05,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(3.0231, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3390, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                       | 41/1000 [00:41<16:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.7989, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4426, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 51/1000 [00:51<16:07,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.6528, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5814, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                      | 61/1000 [01:01<15:56,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.5512, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7202, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                      | 71/1000 [01:11<15:45,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.4714, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8624, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                     | 81/1000 [01:21<15:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.4054, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0073, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                     | 91/1000 [01:31<15:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.3459, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1398, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 101/1000 [01:41<15:06,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.2926, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2815, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                   | 111/1000 [01:51<14:53,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.2453, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4261, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▊                                   | 121/1000 [02:01<14:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.2047, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5773, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                  | 131/1000 [02:11<14:26,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.1691, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7130, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 141/1000 [02:21<14:51,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.1372, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8413, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                  | 151/1000 [02:31<14:09,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.1076, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9616, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                 | 161/1000 [02:41<14:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.0802, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0735, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▊                                 | 171/1000 [02:51<13:47,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "tensor(2.0555, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1743, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                | 180/1000 [03:01<14:07,  1.03s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = GATV3()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(node_feats)  # Perform a single forward pass.\n",
    "      out = out.to(torch.float64)\n",
    "\n",
    "\n",
    "      loss = criterion(out[train_mask], node_labels[train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss_test = criterion(out[val_mask], node_labels[val_mask])\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss, loss_test\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      pred = model(node_feats)\n",
    "      pred = pred.argmax(dim=1)  # Use the class with highest probability.\n",
    "      #true = node_labels.argmax(dim=1)\n",
    "    \n",
    "#       test_acc = torch.sqrt(torch.mean((pred[val_mask] - node_labels[val_mask]) ** 2))\n",
    "#       train_acc = torch.sqrt(torch.mean((pred[train_mask] - node_labels[train_mask]) ** 2))\n",
    "\n",
    "    \n",
    "#       return test_acc.item(), train_acc.item()\n",
    "      return (accuracy_score(node_labels[val_mask], pred[val_mask]),\n",
    "            accuracy_score(node_labels[train_mask], pred[train_mask]))\n",
    "\n",
    "# def train():\n",
    "#       model.train()\n",
    "#       optimizer.zero_grad()  # Clear gradients.\n",
    "#       out = model(node_feats, adj_matrix)  # Perform a single forward pass.\n",
    "#       loss = criterion(out[train_mask], node_labels[train_mask])  # Compute the loss solely based on the training nodes.\n",
    "#       loss_test = criterion(out[val_mask], node_labels[val_mask])\n",
    "#       loss.backward()  # Derive gradients.\n",
    "#       optimizer.step()  # Update parameters based on gradients.\n",
    "#       return loss, loss_test\n",
    "\n",
    "# def test():\n",
    "#       model.eval()\n",
    "#       out = model(node_feats, adj_matrix)\n",
    "#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "#       true = node_labels.argmax(dim=1)\n",
    "#       test_correct = pred[val_mask] == true[val_mask]  # Check against ground-truth labels.\n",
    "#       test_acc = int(np.array(test_correct).sum()) / int(np.array(val_mask).sum())  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "#       train_correct = pred[train_mask] == true[train_mask]  # Check against ground-truth labels.\n",
    "#       train_acc = int(np.array(train_correct).sum()) / int(np.array(train_mask).sum())  # Derive ratio of correct predictions.\n",
    "#       return test_acc, train_acc\n",
    "import tqdm.auto as tqdm\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_aa = []\n",
    "train_aa = []\n",
    "for epoch in tqdm.tqdm(range(1000)):\n",
    "#     if epoch % 100 == 0:\n",
    "#       print(epoch)\n",
    "    loss, loss_test = train()\n",
    "    test_acc, train_acc = test()\n",
    "    train_loss.append(loss.item())\n",
    "    test_loss.append(loss_test.item())\n",
    "    test_aa.append(test_acc)\n",
    "    train_aa.append(train_acc)\n",
    "    if epoch % 10 == 0:\n",
    "        print('train test')\n",
    "        print(loss)\n",
    "        print(loss_test)\n",
    "        print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a9413f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6565, -0.1264, -0.4744],\n",
       "         [-0.7860, -0.2021,  1.3956],\n",
       "         [-0.3140, -0.5562,  0.3549],\n",
       "         [-0.2646, -1.6739,  0.7716]],\n",
       "\n",
       "        [[-0.3312,  0.6003,  0.3360],\n",
       "         [ 0.4989, -0.6734,  1.2114],\n",
       "         [ 1.4119,  0.3367,  0.4190],\n",
       "         [-2.5377,  0.8328, -2.8228]]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(torch.randn(2,3,4), 'a b c -> a c b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd8378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df457726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa5bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f2647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
